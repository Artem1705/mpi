#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    
    int world_rank, world_size;
    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
    MPI_Comm_size(MPI_COMM_WORLD, &world_size);
    
    // Проверяем, что у нас 8 процессов
    if (world_size != 8) {
        if (world_rank == 0) {
            printf("Программа должна быть запущена с 8 процессами!\n");
            printf("Используйте: mpirun -np 8 ./program_name\n");
        }
        MPI_Finalize();
        return 1;
    }
    
    // Определяем соседей в кольцевой топологии
    int left_neighbor = (world_rank - 1 + world_size) % world_size;
    int right_neighbor = (world_rank + 1) % world_size;
    
    // Данные для отправки
    int send_data = world_rank * 100;
    int recv_data_left, recv_data_right;
    
    MPI_Status status;
    
    // Синхронизация перед началом пересылки
    MPI_Barrier(MPI_COMM_WORLD);
    
    if (world_rank == 0) {
        printf("=== НАЧАЛО ПЕРЕСЫЛКИ ДАННЫХ В КОЛЬЦЕ ===\n");
    }
    
    // Пересылка данных по часовой стрелке (вправо)
    if (world_rank == 0) {
        printf("\n=== ПЕРЕСЫЛКА ПО ЧАСОВОЙ СТРЕЛКЕ ===\n");
    }
    
    MPI_Barrier(MPI_COMM_WORLD);
    
    // Процесс 0 начинает пересылку
    if (world_rank == 0) {
        printf("Процесс %d отправляет данные %d процессу %d\n", 
               world_rank, send_data, right_neighbor);
        
        MPI_Send(&send_data, 1, MPI_INT, right_neighbor, 0, MPI_COMM_WORLD);
        
        MPI_Recv(&recv_data_left, 1, MPI_INT, left_neighbor, 0, MPI_COMM_WORLD, &status);
        
        printf("Процесс %d получил данные %d от процесса %d\n", 
               world_rank, recv_data_left, left_neighbor);
    } 
    else {
        MPI_Recv(&recv_data_left, 1, MPI_INT, left_neighbor, 0, MPI_COMM_WORLD, &status);
        
        printf("Процесс %d получил данные %d от процесса %d\n", 
               world_rank, recv_data_left, left_neighbor);
        
        // Модифицируем данные перед отправкой следующему процессу
        send_data = recv_data_left + world_rank;
        
        printf("Процесс %d отправляет данные %d процессу %d\n", 
               world_rank, send_data, right_neighbor);
        
        MPI_Send(&send_data, 1, MPI_INT, right_neighbor, 0, MPI_COMM_WORLD);
    }
    
    // Ждем завершения первой пересылки
    MPI_Barrier(MPI_COMM_WORLD);
    
    // Пересылка данных против часовой стрелки (влево)
    if (world_rank == 0) {
        printf("\n=== ПЕРЕСЫЛКА ПРОТИВ ЧАСОВОЙ СТРЕЛКИ ===\n");
    }
    
    MPI_Barrier(MPI_COMM_WORLD);
    
    // Сбрасываем данные для второй пересылки
    send_data = world_rank * 100 + 50;
    
    // Процесс 0 начинает пересылку в обратном направлении
    if (world_rank == 0) {
        printf("Процесс %d отправляет данные %d процессу %d\n", 
               world_rank, send_data, left_neighbor);
        
        MPI_Send(&send_data, 1, MPI_INT, left_neighbor, 1, MPI_COMM_WORLD);
        
        MPI_Recv(&recv_data_right, 1, MPI_INT, right_neighbor, 1, MPI_COMM_WORLD, &status);
        
        printf("Процесс %d получил данные %d от процесса %d\n", 
               world_rank, recv_data_right, right_neighbor);
    } 
    else {
        MPI_Recv(&recv_data_right, 1, MPI_INT, right_neighbor, 1, MPI_COMM_WORLD, &status);
        
        printf("Процесс %d получил данные %d от процесса %d\n", 
               world_rank, recv_data_right, right_neighbor);
        
        // Модифицируем данные перед отправкой предыдущему процессу
        send_data = recv_data_right + world_rank;
        
        printf("Процесс %d отправляет данные %d процессу %d\n", 
               world_rank, send_data, left_neighbor);
        
        MPI_Send(&send_data, 1, MPI_INT, left_neighbor, 1, MPI_COMM_WORLD);
    }
    
    // Ждем завершения второй пересылки
    MPI_Barrier(MPI_COMM_WORLD);
    
    // Дополнительный пример: пересылка массива данных
    if (world_rank == 0) {
        printf("\n=== ПЕРЕСЫЛКА МАССИВА ДАННЫХ ===\n");
    }
    
    MPI_Barrier(MPI_COMM_WORLD);
    
    const int ARRAY_SIZE = 3;
    int send_array[ARRAY_SIZE];
    int recv_array[ARRAY_SIZE];
    
    // Инициализируем массив для отправки
    for (int i = 0; i < ARRAY_SIZE; i++) {
        send_array[i] = world_rank * 10 + i;
    }
    
    // Используем неблокирующие операции для пересылки массива
    MPI_Request send_request, recv_request;
    
    printf("Процесс %d отправляет массив [", world_rank);
    for (int i = 0; i < ARRAY_SIZE; i++) {
        printf("%d", send_array[i]);
        if (i < ARRAY_SIZE - 1) printf(", ");
    }
    printf("] процессу %d\n", right_neighbor);
    
    MPI_Isend(send_array, ARRAY_SIZE, MPI_INT, right_neighbor, 2, MPI_COMM_WORLD, &send_request);
    MPI_Irecv(recv_array, ARRAY_SIZE, MPI_INT, left_neighbor, 2, MPI_COMM_WORLD, &recv_request);
    
    // Ждем завершения операций
    MPI_Wait(&send_request, &status);
    MPI_Wait(&recv_request, &status);
    
    printf("Процесс %d получил массив [", world_rank);
    for (int i = 0; i < ARRAY_SIZE; i++) {
        printf("%d", recv_array[i]);
        if (i < ARRAY_SIZE - 1) printf(", ");
    }
    printf("] от процесса %d\n", left_neighbor);
    
    // Финальная синхронизация
    MPI_Barrier(MPI_COMM_WORLD);
    
    if (world_rank == 0) {
        printf("\n=== ПЕРЕСЫЛКА ДАННЫХ ЗАВЕРШЕНА ===\n");
    }
    
    MPI_Finalize();
    return 0;
}
